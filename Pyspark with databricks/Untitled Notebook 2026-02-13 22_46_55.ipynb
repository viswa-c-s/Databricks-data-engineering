{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98e5bebc-c500-4b9b-8dbb-6c7d4c85fd05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").options(header='true', inferSchema= 'true')\\\n",
    "    .load(\"/Volumes/dev_data/test/source_raw/source_crm/sales_details.csv\")\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "effa8d8a-9859-455c-8e96-11fe4572e4f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d0d817c-2b9a-4987-a5c2-2b2ade40c794",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_orders = spark.sql(\"select * from dev_data.test.orders_online\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7df495e1-7c78-4145-8629-881b167ced5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_orders.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4683864c-2106-4f45-bdb2-5fa7124861c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_cust = spark.sql(\"select * from dev_data.test.customers_online\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "098ace83-9b4f-4c69-8722-9fec0887b08a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_cust.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc243236-ab77-4360-b1f5-6c6e9fbb0892",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_prod = spark.sql(\"select * from dev_data.test.products\")\n",
    "df_prod.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fcde6de-e836-485c-be52-0caf454d29bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf , col\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def price_category(price):\n",
    "    return \"High\" if price >= 300 else \"Low\"\n",
    "\n",
    "price_udf = udf(price_category, StringType())\n",
    "\n",
    "df_orders.withColumn(\n",
    "    \"price_flag\", price_udf(col(\"order_amount\"))\n",
    ").show()\n",
    "\n",
    "# drawbacks -> UDFs breaks the spark optimizations and can be slow\n",
    "# Slower than built in functions\n",
    "# avoid UDFs when possible and prefer built in spark sql functions performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8919379e-a911-4201-8222-4d0e4815bfac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# we can use built in functions instead of UDF\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "df_orders.withColumn(\n",
    "    \"price_flag\", when(col(\"order_amount\") >= 250, 'High')\\\n",
    "        .otherwise('Low')\n",
    ").show()\n",
    "\n",
    "# using built in functions is faster than UDF\n",
    "# optimized and catalyt-friendly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2db09802-779a-4989-a5e0-856ba276cfd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# pandas udf(Arrow based) - advanced one\n",
    "# use only when logic can't be expressed otherwise\n",
    "\n",
    "from pyspark.sql.functions import pandas_udf , col, round\n",
    "from pyspark.sql.types import DoubleType\n",
    "import pandas as pd\n",
    "\n",
    "@pandas_udf(DoubleType())\n",
    "def tax_udf(amount : pd.Series) -> pd.Series:\n",
    "    return amount * 0.18\n",
    "\n",
    "df_orders.withColumn(\n",
    "    \"tax\", \n",
    "    round(tax_udf(col(\"order_amount\")),2)\n",
    ").show()\n",
    "# pandas udf is faster than python UDFs but still use it only when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "330f17d3-0920-4428-9793-c9a39b250ecc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "explode"
    }
   },
   "outputs": [],
   "source": [
    "# explode() - nexted data essential\n",
    "# used in -> json, arrays, kafka payloads and api data\n",
    "\n",
    "from pyspark.sql.functions import explode\n",
    "\n",
    "data = [\n",
    "    (1, [\"Laptop\", \"Mouse\"]),\n",
    "    (2, [\"Mobile\"])\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data, [\"order_id\", \"Items\"])\n",
    "\n",
    "df.select(\"order_id\", explode(\"Items\").alias(\"item\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd0e7cd4-b98d-45c1-abe7-b3b479062b7d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "split(), concat(), substring()"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, concat, substring, lit\n",
    "\n",
    "data = [\n",
    "    (1, \"Laptop, Mouse\"),\n",
    "    (2, \"Mobile\")\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data, [\"order_id\", \"Items\"])\n",
    "\n",
    "df.withColumn(\"first_item\", split(col(\"Items\"), \",\")).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d55221b-3b7a-4723-b14e-cb90f7d12fd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws\n",
    "df2 = df.withColumn(\n",
    "    \"items_str\", concat_ws(\",\", \"items\")\n",
    ")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52635d49-a4ae-4310-839e-49ecd1fda1bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2026-02-13 22_46_55",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
